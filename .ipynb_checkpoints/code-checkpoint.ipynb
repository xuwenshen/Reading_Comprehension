{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "class UnderstandPassage(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, hidden_size, dropout, voc):\n",
    "        \n",
    "        \n",
    "        super(UnderstandPassage, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dim = self.embedding.size(1)\n",
    "        self.voc = voc\n",
    "        self.voc_size = len(voc)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.enc_net = nn.LSTM(input_size=hidden_size*2,\n",
    "                                hidden_size=hidden_size, \n",
    "                                bias=True)\n",
    "        \n",
    "        self.dec_net = nn.LSTM(input_size=embedding_dim+hidden_size,\n",
    "                                hidden_size=hidden_size, \n",
    "                                bias=True)\n",
    "        \n",
    "        self.fc_net = nn.Linear(hidden_size, self.voc_size)\n",
    "    \n",
    "        self.cost_func = self.init_cost_func()\n",
    "        \n",
    "    def init_cost_func(self):\n",
    "        \n",
    "        weight = [1 for i in range(len(self.voc))]\n",
    "        weight[voc['pad#']] = 0\n",
    "        \n",
    "        return nn.CrossEntropyLoss(weight=torch.Tensor(weight))\n",
    "        \n",
    "    def enc(self, passage_encoders, answer_encoders):\n",
    "        \n",
    "        '''\n",
    "        answer_encoders batch, hidden_size\n",
    "        passage_encoders batch, pn_steps, hidden_size\n",
    "        '''\n",
    "        \n",
    "        answer_encoders = answer_encoders.expand(passage_encoders.size(0), answer_encoders.size(0), self.hidden_size)\n",
    "        inputs = torch.cat([passage_encoders, answer_encoders], -1) # pn_steps, batch, hidden_size*2\n",
    "        \n",
    "        encoders, hidden = self.enc_net(inputs)\n",
    "        encoders = self.dropout(encoders[-1]) #  batch, hidden_size\n",
    "        \n",
    "        return encoders\n",
    "        \n",
    "    def dec(self, encoders, decoder_inputs, is_teacher_forcing, max_question_len):\n",
    "        \n",
    "        '''\n",
    "        if is_teacher_forcing: decoder_inputs (batch, max_question_len)\n",
    "        if not is_teacher_forcing: decoder_inputs (batch, 1)\n",
    "        '''\n",
    "        \n",
    "        decoder_inputs = Variable(decoder_inputs).long().cuda()\n",
    "        decoder_inputs = self.embedding(decoder_inputs)\n",
    "        decoder_inputs = decoder_inputs.transpose(0, 1)\n",
    "        \n",
    "        encoders = encoders.expand(decoder_inputs.size(0), encoders.size(0), self.hidden_size)\n",
    "        inputs = torch.cat([decoder_inputs, encoders], -1)\n",
    "        \n",
    "        if is_teacher_forcing:\n",
    "            \n",
    "            outputs, hidden = self.dec_net(inputs)\n",
    "            outputs = self.dropout(outputs)\n",
    "            logits = self.fc_net(outputs) # qn_steps, batch, voc_size\n",
    "            \n",
    "            _, predictions = torch.max(logits.transpose(0, 1), -1) #batch, qn_steps\n",
    "            predictions = predictions.cpu().data.numpy()\n",
    "            \n",
    "        else:\n",
    "            logits = [0 for i in range(max_question_len)]\n",
    "            predictions = [0 for i in range(max_question_len)]\n",
    "            \n",
    "            output, hidden = self.dec_net(inputs)\n",
    "            output = self.dropout(output)\n",
    "            logits[0] = self.fc_net(output)\n",
    "            \n",
    "            _, index = torch.max(logits[0])\n",
    "            \n",
    "            logits[0] = logits[0].view(1, decoder_inputs.size(1), self.voc_size) # 1，batch_size, voc_size\n",
    "            predictions[0] = index.cpu().data.numpy() # batch_size\n",
    "            \n",
    "            for i in range(1, max_question_len):\n",
    "                \n",
    "                prev_output = Variable(predictions[i-1]).long().cuda()\n",
    "                prev_output = self.embedding(prev_output)\n",
    "                inputs = torch.cat([prev_output, encoders[0]], -1)\n",
    "                \n",
    "                output, hidden = self.dec_net(inputs)\n",
    "                output = self.dropout(output)\n",
    "                logits[i] = self.fc_net(output)\n",
    "\n",
    "                _, index = torch.max(logits[i])\n",
    "                \n",
    "                logits[i] = logits[i].view(1, decoder_inputs.size(0), self.voc_size) # 1，batch_size, voc_size\n",
    "                predictions[i] = index.cpu().data.numpy() # batch_size\n",
    "            \n",
    "            logits = torch.cat(logits)# qn_steps, batch, voc_size\n",
    "            predictions = np.array(predictions).transpose(1, 0)\n",
    "            \n",
    "        return logits, predictions\n",
    "            \n",
    "        \n",
    "    def forward(self, passage_encoders, answer_encoders, decoder_inputs=None, is_teacher_forcing = True, max_question_len=0):\n",
    "        \n",
    "        '''\n",
    "        answer_encoders (batch, an_steps, hidden_size)\n",
    "        passage_encoders (batch, pn_steps, hidden_size)\n",
    "        \n",
    "        if is_teacher_forcing: decoder_inputs (batch, max_question_len)\n",
    "        if not is_teacher_forcing: decoder_inputs (None)\n",
    "        '''\n",
    "        \n",
    "        passage_encoders = passage_encoders.transpose(0, 1) # pn_steps, batch, hidden_size\n",
    "        answer_encoders = answer_encoders.transpose(0, 1) # an_steps, batch, hidden_size\n",
    "        \n",
    "        encoders = self.enc(passage_encoders, answer_encoders)\n",
    "        \n",
    "        if decoder_inputs == None:\n",
    "            decoder_inputs = torch.Tensor([[self.voc['go#']]]*encoders.size(0))\n",
    "        logits, predictions = self.dec(encoders, decoder_inputs, is_teacher_forcing, max_question_len)\n",
    "        \n",
    "    def get_loss(self, logits, labels):\n",
    "        \n",
    "        labels = Variable(labels).long().cuda()\n",
    "        labels = labels.transpose(0, 1)\n",
    "        \n",
    "        logits = logits.contiguous().view(-1, logits.size(-1))\n",
    "        labels = labels.contiguous().view(-1)\n",
    "        \n",
    "        loss = torch.mean(self.cost_func(logits, labels))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "class UnderQuestion(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, hidden_size):\n",
    "        \n",
    "        super(UnderQuestion, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc_net = nn.Linear(hidden_size, 2)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.cost_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    def forward(self, question_encoders, answer_encoders):\n",
    "        \n",
    "        '''\n",
    "        question_encoders  batch, qn_steps, hidden_size\n",
    "        answer_encoders   batch, an_steps, hidden_size\n",
    "        '''\n",
    "        \n",
    "        question_encoders = question_encoders.tranpose(0, 1) #qn_steps, batch, hidden_size\n",
    "        answer_encoders = answer_encoders.tranpose(0, 1) #an_steps, batch, hidden_size\n",
    "        \n",
    "        question_encoders = question_encoders[-1] # batch, hidden_size\n",
    "        answer_encoders = answer_encoders[-1] # batch, hidden_size\n",
    "        \n",
    "        inputs = torch.cat([question_encoders, answer_encoders], -1)\n",
    "        \n",
    "        hidden_layer = self.hidden_layer(inputs)\n",
    "        hidden_layer = self.dropout(hidden_layer)\n",
    "        \n",
    "        logits = self.fc_net(hidden_layer)\n",
    "        _, predictions = torch.max(logits)\n",
    "        predictions = predictions.cpu().data.numpy()\n",
    "        \n",
    "        return logits, predictions\n",
    "        \n",
    "        \n",
    "    def get_loss(self, logits, labels):\n",
    "        \n",
    "        labels = Variable(labels).long().cuda()\n",
    "        loss = self.cost_func(logits, labels)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "embedding_dir = '/data/xuwenshen/workspace/squad/data/train_embedding.json'\n",
    "\n",
    "class MatchLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, dropout):\n",
    "        \n",
    "        super(MatchLayer, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fw_match_lstm = nn.LSTMCell(input_size=hidden_size*2,\n",
    "                                         hidden_size=hidden_size,\n",
    "                                         bias=True)\n",
    "        \n",
    "        self.bw_match_lstm = nn.LSTMCell(input_size=hidden_size*2,\n",
    "                                         hidden_size=hidden_size,\n",
    "                                         bias=True)\n",
    "        \n",
    "        self.whq_net = nn.Linear(hidden_size, hidden_size)\n",
    "        self.whp_net = nn.Linear(hidden_size, hidden_size)\n",
    "        self.whr_net = nn.Linear(hidden_size, hidden_size)\n",
    "        self.w_net = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, passage_encoders, question_encoders):\n",
    "        \n",
    "        passage_encoders = passage_encoders.transpose(0, 1) # pn_steps, batch, hidden_size\n",
    "        question_encoders = question_encoders.transpose(0, 1) # qn_steps, batch, hidden_size\n",
    "        \n",
    "        \n",
    "        wq_matrix = self.whq_net(question_encoders) # qn_steps, batch, hidden_size\n",
    "        wq_matrix = self.dropout(wq_matrix)\n",
    "        \n",
    "        wp_matrix = self.whp_net(passage_encoders) # pn_steps, batch, hidden_size\n",
    "        wp_matrix = self.dropout(wp_matrix)\n",
    "        \n",
    "        # forward match lstm (pn_steps, batch, hidden_size)\n",
    "        fw_match = self.match(passage_encoders, question_encoders, wq_matrix, wp_matrix, fw = True)\n",
    "        \n",
    "        \n",
    "        # backward match lstm (pn_steps, batch, hidden_size)\n",
    "        bw_match = self.match(passage_encoders, question_encoders, wq_matrix, wp_matrix, fw = False)\n",
    "        \n",
    "        match_encoders = torch.cat([fw_match, bw_match], -1) # (pn_steps, batch, hidden_size * 2)\n",
    "        \n",
    "        #print ('fw_match.size(): ', fw_match.size())\n",
    "        #print ('bw_match.size(): ', bw_match.size())\n",
    "        #print ('match_encoders.size(): ', match_encoders.size())\n",
    "        \n",
    "        return match_encoders\n",
    "        \n",
    "    def match(self, passage_encoders, question_encoders, wq_matrix, wp_matrix, fw = True):\n",
    "        \n",
    "        '''\n",
    "        passage_encoders (pn_steps, batch, hidden_size)\n",
    "        question_encoders (qn_steps, batch, hidden_size)\n",
    "        wq_matrix (qn_steps, batch, hidden_size)\n",
    "        wp_matrix (pn_steps, batch, hidden_size)\n",
    "        '''\n",
    "        if fw:\n",
    "            match_lstm = self.fw_match_lstm\n",
    "            start = 0\n",
    "            end = passage_encoders.size(0)\n",
    "            stride = 1\n",
    "        else:\n",
    "            match_lstm = self.bw_match_lstm\n",
    "            start = passage_encoders.size(0) - 1\n",
    "            end = -1\n",
    "            stride = -1\n",
    "        \n",
    "        hx = Variable(torch.zeros(passage_encoders.size(1), self.hidden_size)).cuda()\n",
    "        cx = Variable(torch.zeros(passage_encoders.size(1), self.hidden_size)).cuda()\n",
    "        \n",
    "        match_encoders = [0 for i in range(passage_encoders.size(0))]\n",
    "        \n",
    "        for i in range(start, end, stride):\n",
    "            \n",
    "            wphp = wp_matrix[i]\n",
    "            wrhr = self.whr_net(hx)\n",
    "\n",
    "            _sum = torch.add(wphp, wrhr) # batch, hidden_size\n",
    "            _sum = _sum.expand(wq_matrix.size(0), wq_matrix.size(1), self.hidden_size) # qn_steps, batch, hidden_size\n",
    "            \n",
    "            g = self.tanh(torch.add(wq_matrix, _sum)) # qn_steps, batch, hidden_size\n",
    "\n",
    "            g = torch.transpose(g, 0, 1)# batch, qn_steps, hidden_size\n",
    "            \n",
    "            wg = self.w_net(g) # bactch, qn_steps, 1\n",
    "            wg = wg.squeeze(-1) # bactch, qn_steps\n",
    "            alpha = wg # bactch, qn_steps\n",
    "            alpha = self.softmax(alpha).view(alpha.size(0), 1, alpha.size(1)) # batch,1, qn_steps\n",
    "            \n",
    "            \n",
    "            attentionv = torch.bmm(alpha, question_encoders.transpose(0, 1)) # bacth, 1, hidden_size\n",
    "            attentionv = attentionv.squeeze(1) # bacth, hidden_size\n",
    "            \n",
    "            inp = torch.cat([passage_encoders[i], attentionv], -1)\n",
    "                        \n",
    "            hx, cx = match_lstm(inp, (hx, cx)) # batch, hidden_size\n",
    "            \n",
    "            match_encoders[i] = hx.view(1, hx.size(0), -1)\n",
    "            \n",
    "        match_encoders = torch.cat(match_encoders)\n",
    "        \n",
    "        return match_encoders\n",
    "\n",
    "        \n",
    "class AnswerLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, dropout, passage_len):\n",
    "        \n",
    "        super(AnswerLayer, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.pointer_lstm = nn.LSTMCell(input_size=hidden_size*2,\n",
    "                                        hidden_size=hidden_size, \n",
    "                                        bias=True)\n",
    "        self.vh_net = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.wa_net = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v_net = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.cost_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, match_encoders):\n",
    "        \n",
    "        '''\n",
    "        match_encoders (pn_steps, batch, hidden_size*2)\n",
    "        '''\n",
    "        vh_matrix = self.vh_net(match_encoders) # pn_steps, batch, hidden_size\n",
    "        \n",
    "        # prediction start\n",
    "        h0 = Variable(torch.zeros(match_encoders.size(1), self.hidden_size)).cuda()\n",
    "        c0 = Variable(torch.zeros(match_encoders.size(1), self.hidden_size)).cuda()\n",
    "        \n",
    "        wha1 = self.wa_net(h0) # bacth, hidden_size\n",
    "        wha1 = wha1.expand(match_encoders.size(0), wha1.size(0), wha1.size(1)) # pn_steps, batch, hidden_size\n",
    "        #print ('_sum.size() ', _sum.size())\n",
    "        #print ('vh_matrix.size() ', vh_matrix.size())\n",
    "        f1 = self.tanh(vh_matrix + wha1) # pn_steps, batch, hidden_size\n",
    "        #print ('f1.size() ', f1.size())\n",
    "        vf1 = self.v_net(f1.transpose(0, 1)).squeeze(-1) #batch, pn_steps\n",
    "        \n",
    "        beta1 = self.softmax(vf1) #batch, pn_steps\n",
    "        softmax_beta1 = self.softmax(beta1).view(beta1.size(0), 1, beta1.size(1)) #batch, 1, pn_steps\n",
    "        \n",
    "        inp = torch.bmm(softmax_beta1, match_encoders.transpose(0, 1)) # bacth, 1, hidden_size\n",
    "        inp = inp.squeeze(1) # bacth, hidden_size\n",
    "        \n",
    "        h1, c1 = self.pointer_lstm(inp, (h0, c0))\n",
    "        \n",
    "        \n",
    "        wha2 = self.wa_net(h1) # bacth, hidden_size\n",
    "        wha2 = wha2.expand(match_encoders.size(0), wha2.size(0), wha2.size(1)) # pn_steps, batch, hidden_size\n",
    "        f2 = self.tanh(vh_matrix + wha2) # pn_steps, batch, hidden_size\n",
    "        vf2 = self.v_net(f2.transpose(0, 1)).squeeze(-1) #batch, pn_steps\n",
    "        \n",
    "        beta2 = self.softmax(vf2)#batch, pn_steps\n",
    "        softmax_beta2 = self.softmax(beta2).view(beta2.size(0), 1, beta2.size(1)) #batch, 1, pn_steps\n",
    "        \n",
    "        inp = torch.bmm(softmax_beta2, match_encoders.transpose(0, 1)) # bacth, 1, hidden_size\n",
    "        inp = inp.squeeze(1) # bacth, hidden_size\n",
    "        \n",
    "        h2, c2 = self.pointer_lstm(inp, (h1, c1))\n",
    "            \n",
    "        _, start = torch.max(beta1, 1)\n",
    "        _, end = torch.max(beta2, 1)\n",
    "        \n",
    "        beta1 = beta1.view(1, beta1.size(0), beta1.size(1))\n",
    "        beta2 = beta2.view(1, beta2.size(0), beta2.size(1))\n",
    "        \n",
    "        logits = torch.cat([beta1, beta2])\n",
    "        \n",
    "        start = start.view(1, start.size(0))\n",
    "        end = end.view(1, end.size(0))\n",
    "        \n",
    "        prediction = torch.cat([start, end]).transpose(0, 1).cpu().data.numpy()\n",
    "        \n",
    "\n",
    "        return logits, prediction\n",
    "    \n",
    "    \n",
    "class MatchLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, dropout, passage_len):\n",
    "        \n",
    "        super(MatchLSTM, self).__init__()\n",
    "        \n",
    "        self.match = MatchLayer(hidden_size=hidden_size, dropout=dropout)\n",
    "        self.answer = AnswerLayer(hidden_size=hidden_size, dropout=dropout, passage_len=passage_len)\n",
    "        \n",
    "        self.cost_func = None\n",
    "        \n",
    "    \n",
    "    def forward(self, passage_encoders, question_encoders):\n",
    "        \n",
    "        match_encoders = self.match(passage_encoders, question_encoders)\n",
    "        logits, prediction = self.answer(match_encoders)\n",
    "        \n",
    "        return logits, prediction\n",
    "        \n",
    "    def CrossEntropyLoss(self, logits, labels):\n",
    "        cost_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "        labels = Variable(labels).long().cuda()\n",
    "        labels = labels.transpose(0, 1)\n",
    "        loss = (cost_func(logits[0], labels[0])+ cost_func(logits[1], labels[1])) / 2\n",
    "        \n",
    "        return loss\n",
    "   \n",
    "    def MSELoss(self, logits, labels):\n",
    "        \n",
    "        cost_func = nn.MSELoss(size_average=False)\n",
    "        \n",
    "        ids = labels.transpose(0, 1)\n",
    "        ids = ids.contiguous().view(ids.size(0), ids.size(1), 1)\n",
    "        one_hot = Variable(torch.zeros(logits.size(0), logits.size(1), logits.size(2)).scatter_(-1, ids, 1)).cuda()\n",
    "        \n",
    "        loss = cost_func(logits, one_hot)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def get_loss(self, logits, labels):\n",
    "        \n",
    "        #return self.CrossEntropyLoss(logits, labels)\n",
    "        return self.MSELoss(logits, labels)\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "embedding_dir = '/data/xuwenshen/workspace/squad/data/train_embedding.json'\n",
    "voc = '/data/xuwenshen/workspace/squad/data/voc.json'\n",
    "\n",
    "class PreprocessLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, dropout, embedding_dim):\n",
    "        \n",
    "        super(PreprocessLayer, self).__init__()\n",
    "        \n",
    "        self.passage_lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    num_layers=1,\n",
    "                                    dropout=dropout,\n",
    "                                    batch_first=True)\n",
    "        \n",
    "        self.question_lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=1,\n",
    "                                     dropout=dropout,\n",
    "                                     batch_first=True)\n",
    "        \n",
    "        self.answer_lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=1,\n",
    "                                     dropout=dropout,\n",
    "                                     batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, passage, question, answer = None):\n",
    "        \n",
    "        passage_encoders, p_states = self.passage_lstm(passage)\n",
    "        question_encoders, q_states = self.question_lstm(question)\n",
    "        \n",
    "        if answer == None:\n",
    "            return passage_encoders, question_encoders, None\n",
    "        \n",
    "        answer_encoders, a_states = self.answer_lstm(answer)\n",
    "        return passage_encoders, question_encoders, answer_encoders\n",
    "    \n",
    "    \n",
    "\n",
    "class MultiTask(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        \n",
    "        super(MultiTask, self).__init__(hidden_size, dropout)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = None\n",
    "        self.embedding_dim = None\n",
    "        self.init_embedding()\n",
    "        self.voc = voc\n",
    "        \n",
    "        self.preprocess_layer = PreprocessLayer(hidden_size, dropout, embedding_dim)\n",
    "        self.understandpassage_task = UnderstandPassage(self.embedding, hidden_size, dropout, voc)\n",
    "        self.understandquestion_task = UnderstandQuestion(dropout, hidden_size)\n",
    "        self.match_task = MatchLSTM(hidden_size, dropout, passage_len)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def init_embedding(self):\n",
    "        \n",
    "        pretrained_weight = torch.Tensor(json.load(open(embedding_dir)))\n",
    "        embedding = torch.nn.Embedding(num_embeddings=pretrained_weight.size()[0], embedding_dim=pretrained_weight.size()[1])\n",
    "        embedding.weight = nn.Parameter(pretrained_weight)\n",
    "        embedding.weight.requires_grad = False\n",
    "\n",
    "        self.embedding_dim = pretrained_weight.size()[1]\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        \n",
    "    def preprocess(self, passage, question, answer = None):\n",
    "        \n",
    "        passage = Variable(passage).long().cuda()\n",
    "        question = Variable(question).long().cuda()\n",
    "        \n",
    "        passage = self.embedding(passage)\n",
    "        question = self.embedding(question)\n",
    "        \n",
    "        \n",
    "        if not answer == None:\n",
    "            answer = Variable(answer).long().cuda()\n",
    "            answer = self.embedding(answer)\n",
    "        \n",
    "        passage_encoders, question_encoders, answer_encoders = self.preprocess_layer(passage, question, answer)\n",
    "\n",
    "    def forward(self, passage, question, answer, decoder_inputs, max_question_len, is_generation = True, is_classification = True):\n",
    "        \n",
    "        passage_encoders, question_encoders, answer_encoders = self.preprocess(passage, question, answer)\n",
    "        \n",
    "        generation_logits = None\n",
    "        generation_predictions = None\n",
    "        classification_logits = None\n",
    "        classification_predictions = None\n",
    "        macth_logits = None\n",
    "        match_predictions = None\n",
    "        \n",
    "        if is_generation:\n",
    "            generation_logits, generation_predictions = self.understandpassage_task(passage_encoders, answer_encoders, \n",
    "                                                                                    decoder_inputs,\n",
    "                                                                                    is_teacher_forcing, max_question_len)\n",
    "            \n",
    "        if is_classification:\n",
    "            classification_logits, classification_predictions = self.understandquestion_task(question_encoders, answer_encoders)\n",
    "            \n",
    "        macth_logits, match_predictions = self.match_task(passage_encoders, question_encoders)\n",
    "        \n",
    "        return {'generation_logits':generation_logits,\n",
    "                'generation_predictions':generation_predictions,\n",
    "                'classification_logits':classification_logits,\n",
    "                'classification_predictions':classification_predictions,\n",
    "                'macth_logits':macth_logits,\n",
    "                'match_predictions':match_predictions}\n",
    "    \n",
    "    def get_loss(self, match_logits, match_labels, generation_logits, generation_labels, classification_logits, \n",
    "                 classification_labels, is_generation = True, is_classification = True):\n",
    "        \n",
    "        generation_loss = None\n",
    "        match_loss = None\n",
    "        classification_loss = None\n",
    "        \n",
    "        if is_generation:\n",
    "            generation_loss = self.understandpassage_task.get_loss(generation_logits, generation_labels)\n",
    "        if is_classification:\n",
    "            classification_loss = self.understandquestion_task.get_loss(classification_logits, classification_labels)\n",
    "        \n",
    "        match_loss = self.match_task.get_loss(macth_logits, match_labels)\n",
    "        \n",
    "        return {'generation_loss':generation_loss,\n",
    "                'match_loss':match_loss,\n",
    "                'classification_loss':classification_loss}\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
